{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMc8NukS75QBfeCAhFPnLNn"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"vrX3_doXjKvm","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1748892165351,"user_tz":-330,"elapsed":359195,"user":{"displayName":"Akshada Gunjal","userId":"17152451300241560849"}},"outputId":"c7331f26-9293-490e-a82a-25d88175a1ef"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.2.10)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (5.29.4)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.2.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.1.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.13.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.71.0)\n","Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n","Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n","Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.13.0)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n","Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n","Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.4.26)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.8)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n","Dataset loaded successfully with 15 classes: ['l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z']\n","Training samples: 8430, Test samples: 0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n","  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/15\n","\u001b[1m264/264\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 228ms/step - accuracy: 0.7208 - loss: 0.9047"]},{"output_type":"error","ename":"ValueError","evalue":"Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(32, 1), dtype=float32). Expected shape (None, 64, 64, 1), but input has incompatible shape (32, 1)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 1), dtype=float32)\n  • training=False\n  • mask=None","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-9e7126aa9080>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m history = model.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m    104\u001b[0m                    \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                    \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/models/functional.py\u001b[0m in \u001b[0;36m_adjust_input_rank\u001b[0;34m(self, flat_inputs)\u001b[0m\n\u001b[1;32m    270\u001b[0m                     \u001b[0madjusted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m                     \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    273\u001b[0m                 \u001b[0;34mf\"Invalid input shape for input {x}. Expected shape \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m                 \u001b[0;34mf\"{ref_shape}, but input has incompatible shape {x.shape}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Exception encountered when calling Sequential.call().\n\n\u001b[1mInvalid input shape for input Tensor(\"data:0\", shape=(32, 1), dtype=float32). Expected shape (None, 64, 64, 1), but input has incompatible shape (32, 1)\u001b[0m\n\nArguments received by Sequential.call():\n  • inputs=tf.Tensor(shape=(32, 1), dtype=float32)\n  • training=False\n  • mask=None"]}],"source":["# Step 1: Mount Google Drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Step 2: Install required packages\n","!pip install opencv-python numpy tensorflow pillow\n","\n","# Step 3: Import libraries\n","import os\n","import cv2\n","import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.utils import to_categorical\n","from sklearn.preprocessing import LabelEncoder\n","from PIL import Image\n","import matplotlib.pyplot as plt\n","from IPython.display import display, Javascript, HTML\n","import ipywidgets as widgets\n","from datetime import datetime, time\n","\n","# Step 4: Load and prepare dataset\n","def load_dataset(dataset_path):\n","    X_train, y_train = [], []\n","    X_test, y_test = [], []\n","\n","    # Load training data\n","    train_path = os.path.join(dataset_path, 'train')\n","    for class_name in os.listdir(train_path):\n","        class_path = os.path.join(train_path, class_name)\n","        for img_file in os.listdir(class_path):\n","            img_path = os.path.join(class_path, img_file)\n","            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","            img = cv2.resize(img, (64, 64))\n","            X_train.append(img)\n","            y_train.append(class_name)\n","\n","    # Load test data\n","    test_path = os.path.join(dataset_path, 'test')\n","    for class_name in os.listdir(test_path):\n","        class_path = os.path.join(test_path, class_name)\n","        for img_file in os.listdir(class_path):\n","            img_path = os.path.join(class_path, img_file)\n","            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n","            img = cv2.resize(img, (64, 64))\n","            X_test.append(img)\n","            y_test.append(class_name)\n","\n","    # Convert to numpy arrays\n","    X_train = np.array(X_train)\n","    X_test = np.array(X_test)\n","\n","    # Encode labels\n","    le = LabelEncoder()\n","    y_train = le.fit_transform(y_train)\n","    y_test = le.transform(y_test)\n","\n","    # One-hot encode\n","    num_classes = len(le.classes_)\n","    y_train = to_categorical(y_train, num_classes)\n","    y_test = to_categorical(y_test, num_classes)\n","\n","    # Normalize and reshape\n","    X_train = X_train.astype('float32') / 255.0\n","    X_test = X_test.astype('float32') / 255.0\n","    X_train = np.expand_dims(X_train, axis=-1)\n","    X_test = np.expand_dims(X_test, axis=-1)\n","\n","    return (X_train, y_train), (X_test, y_test), le.classes_\n","\n","# Update this path to your dataset location in Google Drive\n","dataset_path = '/content/drive/MyDrive/Colab_Notebooks/isl_data_grey_split'\n","(X_train, y_train), (X_test, y_test), class_names = load_dataset(dataset_path)\n","\n","print(f\"Dataset loaded successfully with {len(class_names)} classes: {class_names}\")\n","print(f\"Training samples: {X_train.shape[0]}, Test samples: {X_test.shape[0]}\")\n","\n","# Step 5: Create and train the model\n","def create_model(input_shape, num_classes):\n","    model = Sequential([\n","        Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n","        MaxPooling2D(2,2),\n","        Conv2D(64, (3,3), activation='relu'),\n","        MaxPooling2D(2,2),\n","        Conv2D(128, (3,3), activation='relu'),\n","        MaxPooling2D(2,2),\n","        Flatten(),\n","        Dense(256, activation='relu'),\n","        Dropout(0.5),\n","        Dense(num_classes, activation='softmax')\n","    ])\n","\n","    model.compile(optimizer='adam',\n","                 loss='categorical_crossentropy',\n","                 metrics=['accuracy'])\n","    return model\n","\n","input_shape = X_train.shape[1:]\n","num_classes = len(class_names)\n","model = create_model(input_shape, num_classes)\n","\n","history = model.fit(X_train, y_train,\n","                   validation_data=(X_test, y_test),\n","                   epochs=15,\n","                   batch_size=32)\n","\n","# Step 6: Evaluate the model\n","test_loss, test_acc = model.evaluate(X_test, y_test)\n","print(f\"\\nTest Accuracy: {test_acc*100:.2f}%\")\n","\n","# Plot training history\n","plt.figure(figsize=(12, 4))\n","plt.subplot(1, 2, 1)\n","plt.plot(history.history['accuracy'], label='Train Accuracy')\n","plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n","plt.title('Accuracy over epochs')\n","plt.legend()\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(history.history['loss'], label='Train Loss')\n","plt.plot(history.history['val_loss'], label='Val Loss')\n","plt.title('Loss over epochs')\n","plt.legend()\n","plt.show()\n","\n","# Step 7: Save the model\n","model.save('/content/drive/MyDrive/Colab_Notebooks/sign_language_model.h5')\n","print(\"Model saved to Google Drive\")\n","\n","# Step 8: Real-time detection functions\n","def is_operational():\n","    now = datetime.now().time()\n","    start_time = time(18, 0)  # 6 PM\n","    end_time = time(22, 0)    # 10 PM\n","    return start_time <= now <= end_time\n","\n","def predict_image(img_array):\n","    img = cv2.resize(img_array, (64, 64))\n","    img = img.astype('float32') / 255.0\n","    img = np.expand_dims(img, axis=0)\n","    img = np.expand_dims(img, axis=-1)\n","    prediction = model.predict(img)\n","    return class_names[np.argmax(prediction)]\n","\n","# Step 9: Create Colab interface\n","from IPython.display import display, clear_output\n","import ipywidgets as widgets\n","\n","# Image upload function\n","def upload_image(change):\n","    if not is_operational():\n","        print(\"Service only available from 6 PM to 10 PM\")\n","        return\n","\n","    for file in uploader.value:\n","        content = file['content']\n","        with open('temp.jpg', 'wb') as f:\n","            f.write(content)\n","\n","        img = cv2.imread('temp.jpg', cv2.IMREAD_GRAYSCALE)\n","        prediction = predict_image(img)\n","\n","        # Display image and prediction\n","        display_img = Image.open('temp.jpg')\n","        plt.imshow(display_img, cmap='gray')\n","        plt.title(f\"Predicted: {prediction}\")\n","        plt.axis('off')\n","        plt.show()\n","\n","# Camera capture function\n","def capture_image(button):\n","    if not is_operational():\n","        print(\"Service only available from 6 PM to 10 PM\")\n","        return\n","\n","    # JavaScript to access webcam\n","    js = Javascript('''\n","        async function capture() {\n","            const div = document.createElement('div');\n","            const video = document.createElement('video');\n","            video.style.display = 'block';\n","            const stream = await navigator.mediaDevices.getUserMedia({video: true});\n","\n","            document.body.appendChild(div);\n","            div.appendChild(video);\n","            video.srcObject = stream;\n","            await video.play();\n","\n","            // Resize the output to fit the video element.\n","            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n","\n","            // Wait for Capture button to be clicked.\n","            await new Promise((resolve) => {\n","                const button = document.createElement('button');\n","                button.textContent = 'Capture';\n","                button.style.display = 'block';\n","                button.style.margin = '10px auto';\n","                div.appendChild(button);\n","\n","                button.onclick = () => {\n","                    const canvas = document.createElement('canvas');\n","                    canvas.width = video.videoWidth;\n","                    canvas.height = video.videoHeight;\n","                    canvas.getContext('2d').drawImage(video, 0, 0);\n","                    stream.getVideoTracks()[0].stop();\n","                    div.remove();\n","                    resolve(canvas.toDataURL('image/jpeg'));\n","                };\n","            });\n","        }\n","        await capture();\n","        ''')\n","\n","    # Display the JavaScript\n","    display(js)\n","\n","    # Convert the image data to a numpy array\n","    def process_image(image_data):\n","        # Decode the base64 image data\n","        from base64 import b64decode\n","        import io\n","        image_bytes = b64decode(image_data.split(',')[1])\n","        image = Image.open(io.BytesIO(image_bytes))\n","        image.save('capture.jpg', 'JPEG')\n","\n","        # Process and predict\n","        img = cv2.imread('capture.jpg', cv2.IMREAD_GRAYSCALE)\n","        prediction = predict_image(img)\n","\n","        # Display results\n","        clear_output()\n","        plt.imshow(image, cmap='gray')\n","        plt.title(f\"Predicted: {prediction}\")\n","        plt.axis('off')\n","        plt.show()\n","\n","    # Register callback\n","    js.on_done(process_image)\n","\n","# Create widgets\n","uploader = widgets.FileUpload(accept='image/*', multiple=False)\n","upload_button = widgets.Button(description=\"Upload Image\")\n","capture_button = widgets.Button(description=\"Capture from Camera\")\n","\n","upload_button.on_click(lambda b: upload_image(None))\n","capture_button.on_click(capture_image)\n","\n","# Display the interface\n","print(\"## Sign Language Detection (6PM-10PM) ##\")\n","display(uploader)\n","display(upload_button)\n","display(capture_button)"]}]}